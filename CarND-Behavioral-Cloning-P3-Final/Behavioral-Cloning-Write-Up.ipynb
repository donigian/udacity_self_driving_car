{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Behavioral Cloning Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "+ Use the simulator to collect data of good driving behavior\n",
    "+ Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "+ Train and validate the model with a training and validation set\n",
    "+ Test that the model successfully drives around track one without leaving the road\n",
    "+ Summarize the results with a written report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video recording of a test drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link to video](https://youtu.be/2bbZJGtuk_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"./final_model.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"./final_model.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture and Training Strategy\n",
    "### 1) An appropriate model architecture has been employed\n",
    "\n",
    "My model embraces transfer learning and as a result is motivated by [a paper from Nvidia](https://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf). The model includes RELU layers to introduce nonlinearity, and the data is normalized in the model using a Keras lambda layer.\n",
    "\n",
    "**Layers:**\n",
    "\n",
    "+ **Lambda** - normalization layer\n",
    "+ **Convolution2D** - convolution with 5x5 & 3x3 kernels, padding valid and RELU activation.\n",
    "+ **MaxPooling2D** - useful to reduce dimensions\n",
    "+ **Dropout** - prevents overfiting\n",
    "+ **Cropping2D** - remove irrelevant parts of image\n",
    "+ **Flatten** - converting output of convolutional part of the CNN into a 1 dimensional feature vector\n",
    "+ **Dense** - regression output (steering angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "____________________________________________________________________________________________________\n",
    "Layer (type)                     Output Shape          Param #     Connected to\n",
    "====================================================================================================\n",
    "lambda_1 (Lambda)                (None, 160, 320, 3)   0           lambda_input_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_1 (Convolution2D)  (None, 80, 160, 24)   1824        lambda_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_1 (Activation)        (None, 80, 160, 24)   0           convolution2d_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "maxpooling2d_1 (MaxPooling2D)    (None, 79, 159, 24)   0           activation_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_2 (Convolution2D)  (None, 40, 80, 36)    21636       maxpooling2d_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_2 (Activation)        (None, 40, 80, 36)    0           convolution2d_2[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "maxpooling2d_2 (MaxPooling2D)    (None, 39, 79, 36)    0           activation_2[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_3 (Convolution2D)  (None, 20, 40, 48)    43248       maxpooling2d_2[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_3 (Activation)        (None, 20, 40, 48)    0           convolution2d_3[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "maxpooling2d_3 (MaxPooling2D)    (None, 19, 39, 48)    0           activation_3[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_4 (Convolution2D)  (None, 19, 39, 64)    27712       maxpooling2d_3[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_4 (Activation)        (None, 19, 39, 64)    0           convolution2d_4[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "maxpooling2d_4 (MaxPooling2D)    (None, 18, 38, 64)    0           activation_4[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "convolution2d_5 (Convolution2D)  (None, 18, 38, 64)    36928       maxpooling2d_4[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_5 (Activation)        (None, 18, 38, 64)    0           convolution2d_5[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "maxpooling2d_5 (MaxPooling2D)    (None, 17, 37, 64)    0           activation_5[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "flatten_1 (Flatten)              (None, 40256)         0           maxpooling2d_5[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "dense_1 (Dense)                  (None, 1164)          46859148    flatten_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_6 (Activation)        (None, 1164)          0           dense_1[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "dense_2 (Dense)                  (None, 100)           116500      activation_6[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_7 (Activation)        (None, 100)           0           dense_2[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "dense_3 (Dense)                  (None, 50)            5050        activation_7[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_8 (Activation)        (None, 50)            0           dense_3[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "dense_4 (Dense)                  (None, 10)            510         activation_8[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "activation_9 (Activation)        (None, 10)            0           dense_4[0][0]\n",
    "____________________________________________________________________________________________________\n",
    "dense_5 (Dense)                  (None, 1)             11          activation_9[0][0]\n",
    "====================================================================================================\n",
    "Total params: 47,112,567\n",
    "Trainable params: 47,112,567\n",
    "Non-trainable params: 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Attempts to reduce overfitting in the model\n",
    "The model contains dropout layers in order to reduce overfitting.\n",
    "\n",
    "The model was trained and validated on different data sets to ensure that the model was not overfitting. The model was tested by running it through the simulator and ensuring that the vehicle could stay on the track."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3) Model parameter tuning\n",
    "The model used an adam optimizer and I experimented with various values for learning rate ([.1, .01, .001, .0001]) and settled on .0001 since it resulted in the least validation loss. \n",
    "\n",
    "The following hyperparameters minimized validation loss:\n",
    "+ learning rate: .0001\n",
    "+ number of epochs: 12\n",
    "+ batch size: 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 1/12\n",
    "6336/6428 [============================>.] - ETA: 3s - loss: \n",
    "6432/6428 [==============================] - 285s - loss: 0.0423 - val_loss: 0.0121\n",
    "Epoch 2/12\n",
    "6432/6428 [==============================] - 283s - loss: 0.0130 - val_loss: 0.0100\n",
    "Epoch 3/12\n",
    "6516/6428 [==============================] - 286s - loss: 0.0104 - val_loss: 0.0099\n",
    "Epoch 4/12\n",
    "6432/6428 [==============================] - 282s - loss: 0.0106 - val_loss: 0.0087\n",
    "Epoch 5/12\n",
    "6432/6428 [==============================] - 282s - loss: 0.0099 - val_loss: 0.0102\n",
    "Epoch 6/12\n",
    "6516/6428 [==============================] - 286s - loss: 0.0090 - val_loss: 0.0082\n",
    "Epoch 7/12\n",
    "6432/6428 [==============================] - 282s - loss: 0.0095 - val_loss: 0.0104\n",
    "Epoch 8/12\n",
    "6432/6428 [==============================] - 283s - loss: 0.0089 - val_loss: 0.0086\n",
    "Epoch 9/12\n",
    "6516/6428 [==============================] - 287s - loss: 0.0083 - val_loss: 0.0111\n",
    "Epoch 10/12\n",
    "6432/6428 [==============================] - 291s - loss: 0.0090 - val_loss: 0.0081\n",
    "Epoch 11/12\n",
    "6432/6428 [==============================] - 295s - loss: 0.0080 - val_loss: 0.0092\n",
    "Epoch 12/12\n",
    "6516/6428 [==============================] - 300s - loss: 0.0078 - val_loss: 0.0081\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 4) Appropriate training data\n",
    "The training data is [provided](https://d17h27t6h515a5.cloudfront.net/topher/2016/December/584f6edd_data/data.zip) by Udacity. I made several attempts to collect and augment my own training data but it didn't yield better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Architecture and Training Strategy\n",
    "\n",
    "### 1) Solution Design Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The overall strategy for deriving a model architecture was iterative. My first step after downloading the simulator, was to drive the vehicle manually for a few laps to get a feel for the controls and get better at track 1. My ability to manually drive the vehicle would be porportional to the quality of the training samples produced. I recorded one lap for an initial end to end test scenario prior to implementing the full CNN architecture.\n",
    "\n",
    "The second step was to use a very simple convolution neural network sequential model with one flat and dense layers. I thought this model might be appropriate since I was primarily interested in and end-to-end test scenario to define a workflow for training and get familiar with the tools provided.\n",
    "\n",
    "After training this initial model, the vehicle performed as expected, poorly. The next step was to gather more training data and perform image processing. In addition, I downloaded the training dataset available from Udacity for augmentation as well. Here are some processing steps taken:\n",
    "\n",
    "+ cropping images to remove top part of the image which isn't necessary\n",
    "+ using multiple cameras in addition to center image\n",
    "+ flip images horizontally\n",
    "+ added an angle offset of +/- 0.4 to the steering angle (recovery driving)\n",
    "\n",
    "In order to gauge how well the model was working, I split my image and steering angle data into a training and validation set. I found that my first model had a low mean squared error on the training set but a high mean squared error on the validation set. This implied that the model was overfitting.\n",
    "\n",
    "To combat the overfitting, I modified the model to include dropout.\n",
    "\n",
    "Then I looked at the Nvidia paper (mentioned above) for a reference architecture and integrated it into this project.\n",
    "\n",
    "I ran into a memory error after a sufficiently large number of training samples, so I refactored my model training to use generators and train on batches of images instead of having to load the entire data into memory.\n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one. There were a few spots where the vehicle fell off the track. Inorder to improve the driving behavior in these cases, I recorded some recovery driving images and retrained the model. \n",
    "\n",
    "At the end of the process, the vehicle is able to drive autonomously around the track without leaving the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Final Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNN Architecture](./assets/cnn_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Creation of the Training Set & Training Process\n",
    "To capture good driving behavior, I first recorded few laps on track one using center lane driving. Here is an example image of center lane driving:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![CNN Architecture](./assets/center_2017_03_15_07_36_35_267.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then recorded the vehicle recovering from the left side and right sides of the road back to center so that the vehicle would learn to stay in the lane and be more generalizable. These images show what a recovery looks like starting from ... :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steering angle:0\n",
    "![CNN Architecture](./assets/center_2016_12_01_13_30_48_287.jpg)\n",
    "\n",
    "Steering angle:0\n",
    "![CNN Architecture](./assets/center_2016_12_01_13_31_13_381.jpg)\n",
    "\n",
    "Steering angle: 0.5784606\n",
    "![CNN Architecture](./assets/left_2016_12_01_13_32_43_963.jpg)\n",
    "\n",
    "Steering angle: 0.0904655\n",
    "![CNN Architecture](./assets/right_2016_12_01_13_32_45_477.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used this training data for training the model. The validation set helped determine if the model was over or under fitting. Here are the model hyperparameter values:\n",
    "\n",
    "+ learning rate: .0001\n",
    "+ number of epochs: 12\n",
    "+ batch size: 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the collection process, I had 12K number of data points.  I finally randomly shuffled the data set and put Y% of the data into a validation set.\n",
    "```\n",
    "Number of negative steering angles: 1775 \n",
    "Number of positive steering angles:1900 \n",
    "Number of zero steering angles:4361\n",
    "```\n",
    "\n",
    "Steering angles distribution plot:\n",
    "![CNN Architecture](./assets/angles_distribution_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A test set wasn't necessary since the purpose of a test set is to measure the model's ability to generalize but the purpose is satisfied by running the final model on the test track in the game simulation.\n",
    "\n",
    "Since it isn't possible to store all images in memory, I used a python generator to generate batches of data. Only a list of filenames of the entire training and validation set were stored in memory, and the images themselves were read from disk only when new batch was requested.\n",
    "\n",
    "An adam optimizer (https://arxiv.org/abs/1412.6980v8) was used to minimize the mean squared error (MSE). The evaluation metric (loss function) used is MSE since the project requires predicting steering angles which is a regression problem."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
